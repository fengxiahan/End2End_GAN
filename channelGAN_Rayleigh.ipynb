{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSlxWrR6zoDrV3I4GmAs0m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fengxiahan/End2End_GAN/blob/master/channelGAN_Rayleigh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12OtCgnr_SCf",
        "outputId": "41f67aa0-9963-4740-cdfb-9edb6a9efe94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'End2End_GAN' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/fengxiahan/End2End_GAN.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
        "\n",
        "\"\"\" This file is trying to simulate the Rayleigh channel without any channel information\"\"\"\n",
        "\n",
        "tf.random.set_seed(100)\n",
        "np.random.seed(100)\n",
        "\n",
        "def generator_conditional(z, conditioning):  # need to change the structure\n",
        "    z_combine = tf.keras.layers.Concatenate(axis=1)([z, conditioning])\n",
        "    G_h1 = tf.nn.relu(tf.matmul(z_combine, G_W1) + G_b1)\n",
        "    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)\n",
        "    G_h3 = tf.nn.relu(tf.matmul(G_h2, G_W3) + G_b3)\n",
        "    G_logit = tf.matmul(G_h3, G_W4) + G_b4\n",
        "    return G_logit\n",
        "\n",
        "\n",
        "def discriminator_conditional(X,  conditioning):  # need to change the structure\n",
        "    z_combine = tf.concat([X, conditioning], 1)\n",
        "    D_h1_real = tf.nn.relu(tf.matmul(z_combine / 4, D_W1) + D_b1)\n",
        "    #D_h2_real = tf.reduce_mean(tf.nn.relu(tf.matmul(D_h1_real, D_W2) + D_b2), axis=0, keep_dims=True)\n",
        "    D_h2_real = tf.nn.relu(tf.matmul(D_h1_real, D_W2) + D_b2)\n",
        "    D_h3_real = tf.nn.relu(tf.matmul(D_h2_real, D_W3) + D_b3)\n",
        "    D_logit = tf.matmul(D_h3_real, D_W4) + D_b4\n",
        "    D_prob = tf.nn.sigmoid(D_logit)\n",
        "    return D_prob, D_logit\n",
        "\n",
        "\n",
        "def sample_Z(sample_size):\n",
        "    ''' Sampling the generation noise Z from normal distribution '''\n",
        "    return np.random.normal(size=sample_size)\n",
        "\n",
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random.normal(shape=size, stddev=xavier_stddev)\n"
      ],
      "metadata": {
        "id": "rp_Y_7ldQYas"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "下面用于模拟瑞利衰落信道中的数据生成过程，特别是针对带有标签的真实数据采样。"
      ],
      "metadata": {
        "id": "FvxpEjWJ_Lip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number = 200\n",
        "h_r = np.random.normal(scale=np.sqrt(2) / 2, size=number)\n",
        "h_i = np.random.normal(scale=np.sqrt(2) / 2, size=number)\n",
        "h_complex = h_r + 1j * h_i"
      ],
      "metadata": {
        "id": "uiAXbtk6_Sny"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_real_samples_with_labels_Rayleigh(number=100):\n",
        "    h_r = np.random.normal(scale=np.sqrt(2) / 2, size=number)\n",
        "    h_i = np.random.normal(scale=np.sqrt(2) / 2, size=number)\n",
        "    h_complex = h_r + 1j * h_i\n",
        "    labels_index = np.random.choice(len(mean_set_QAM), number)\n",
        "    data = mean_set_QAM[labels_index]\n",
        "    received_data = h_complex * data\n",
        "    received_data = np.hstack(\n",
        "        (np.real(received_data).reshape(len(data), 1), np.imag(received_data).reshape(len(data), 1)))\n",
        "    gaussion_random = np.random.multivariate_normal([0, 0], [[0.01, 0], [0, 0.01]], number).astype(np.float32)\n",
        "    received_data = received_data + gaussion_random\n",
        "    conditioning = np.hstack((np.real(data).reshape(len(data), 1), np.imag(data).reshape(len(data), 1),\n",
        "                              h_r.reshape(len(data), 1), h_i.reshape(len(data), 1))) / 3\n",
        "    return received_data, conditioning\n"
      ],
      "metadata": {
        "id": "0YuCeODHA-9b"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\" ==== Here is the main function ==== \"\"\"\n"
      ],
      "metadata": {
        "id": "3yL6dt38BShc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_set_QAM = np.asarray([-3 - 3j, -3 - 1j, -3 + 1j, -3 + 3j, -1 - 3j, -1 - 1j, -1 + 1j, -1 + 3j,\n",
        "                           1 - 3j, 1 - 1j, 1 + 1j, 1 + 3j, 3 - 3j, 3 - 1j, 3 + 1j, 3 + 3j\n",
        "                           ], dtype=np.complex64)\n",
        "batch_size = 512\n",
        "condition_depth = 2\n",
        "condition_dim = 4\n",
        "Z_dim = 16\n",
        "model = 'ChannelGAN_Rayleigh_'\n",
        "data_size = 10000\n",
        "data, one_hot_labels = generate_real_samples_with_labels_Rayleigh(data_size)"
      ],
      "metadata": {
        "id": "yxu9SWujBUO4"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_W1 = tf.Variable(xavier_init([2 + condition_dim, 32]))\n",
        "D_b1 = tf.Variable(tf.zeros(shape=[32]))\n",
        "D_W2 = tf.Variable(xavier_init([32, 32]))\n",
        "D_b2 = tf.Variable(tf.zeros(shape=[32]))\n",
        "D_W3 = tf.Variable(xavier_init([32, 32]))\n",
        "D_b3 = tf.Variable(tf.zeros(shape=[32]))\n",
        "D_W4 = tf.Variable(xavier_init([32, 1]))\n",
        "D_b4 = tf.Variable(tf.zeros(shape=[1]))\n",
        "theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3, D_W4, D_b4]\n",
        "G_W1 = tf.Variable(xavier_init([Z_dim + condition_dim, 128]))\n",
        "G_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
        "G_W2 = tf.Variable(xavier_init([128, 128]))\n",
        "G_b2 = tf.Variable(tf.zeros(shape=[128]))\n",
        "G_W3 = tf.Variable(xavier_init([128, 128]))\n",
        "G_b3 = tf.Variable(tf.zeros(shape=[128]))\n",
        "G_W4 = tf.Variable(xavier_init([128, 2]))\n",
        "G_b4 = tf.Variable(tf.zeros(shape=[2]))\n",
        "theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3, G_W4, G_b4]"
      ],
      "metadata": {
        "id": "DEvr6lL9CjNq"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_sample = tf.compat.v1.placeholder(tf.float32, shape=[None, 2])\n",
        "Z = tf.compat.v1.placeholder(tf.float32, shape=[None, Z_dim])\n",
        "Condition = tf.compat.v1.placeholder(tf.float32, shape=[None, condition_dim])"
      ],
      "metadata": {
        "id": "WGkfB-tlDdiH"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_sample = generator_conditional(Z, Condition)\n",
        "D_prob_real, D_logit_real = discriminator_conditional(R_sample, Condition)\n",
        "D_prob_fake, D_logit_fake = discriminator_conditional(G_sample, Condition)"
      ],
      "metadata": {
        "id": "oAJBuFeBIPU6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_sample = generator_conditional(Z, Condition)\n",
        "D_prob_real, D_logit_real = discriminator_conditional(R_sample, Condition)\n",
        "D_prob_fake, D_logit_fake = discriminator_conditional(G_sample, Condition)\n",
        "\n",
        "D_loss = tf.reduce_mean(D_logit_fake) - tf.reduce_mean(D_logit_real)\n",
        "G_loss = -1 * tf.reduce_mean(D_logit_fake)\n",
        "lambdda = 5\n",
        "alpha = tf.random.uniform(shape=tf.shape(R_sample), minval=0., maxval=1.)\n",
        "differences = G_sample - R_sample\n",
        "interpolates = R_sample + (alpha * differences)\n",
        "_, D_inter = discriminator_conditional(interpolates, Condition)\n",
        "gradients = tf.gradients(D_inter, [interpolates])[0]\n",
        "slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=1))\n",
        "gradient_penalty = tf.reduce_mean((slopes - 1.0) ** 2)\n",
        "D_loss += lambdda * gradient_penalty\n",
        "D_solver = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9)\n",
        "G_solver = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9)\n",
        "\n",
        "sess = tf.compat.v1.Session()\n",
        "sess.run(tf.compat.v1.global_variables_initializer())"
      ],
      "metadata": {
        "id": "7Icbcl7wNzOx"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_fig_path = model + \"images\"\n",
        "if not os.path.exists(save_fig_path):\n",
        "    os.makedirs(save_fig_path)"
      ],
      "metadata": {
        "id": "BQ3XkGQ7PCSx"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.plot(data[:1000, 0], data[:1000, 1], 'b.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkL6ZeBzPLxx",
        "outputId": "8d7df478-e4be-470e-90e8-b91dad16c8f8"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x79f9383519f0>]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np_samples = []\n",
        "plot_every = 1000\n",
        "plt.figure(figsize=(5, 5))\n",
        "xmax = 4\n",
        "saver = tf.compat.v1.train.Saver()"
      ],
      "metadata": {
        "id": "cki5ZeL4Pkpe"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "for it in range(1200):\n",
        "    start_idx = it * batch_size % data_size\n",
        "    if start_idx + batch_size >= len(data):\n",
        "        continue\n",
        "    X_mb = data[start_idx:start_idx + batch_size, :]\n",
        "    one_hot_labels_mb = one_hot_labels[start_idx:start_idx + batch_size, :]\n",
        "    for d_idx in range(2):\n",
        "        _, D_loss_curr = sess.run([D_solver.minimize(D_loss), D_loss],\n",
        "                              feed_dict={R_sample: X_mb, Z: sample_Z((batch_size, Z_dim)),\n",
        "                                         Condition: one_hot_labels_mb})\n",
        "\n",
        "    _, G_loss_curr = sess.run([G_solver.minimize(G_loss), G_loss],\n",
        "                              feed_dict={R_sample: X_mb, Z: sample_Z((batch_size, Z_dim)), Condition: one_hot_labels_mb})\n",
        "\n",
        "\n",
        "    if (it + 1) % plot_every == 0:\n",
        "        save_path = saver.save(sess, './Models/ChannelGAN_model_step_' + str(it) + '.ckpt')\n",
        "\n",
        "\n",
        "        print(\"Start Plotting\")\n",
        "        colors = ['b.', 'r+', 'm.', 'c.', 'k.', 'g.', 'y.', 'm.', \\\n",
        "                  'bo', 'ro', 'mo', 'co', 'ko', 'go', 'yo', 'bo']\n",
        "        colors = ['b.', 'b+', 'bx', 'b^', 'b^', 'bx', 'b+', 'b.', \\\n",
        "                  'b.', 'b+', 'bx', 'b^', 'b^', 'bx', 'b+', 'b.']\n",
        "        plt.clf()\n",
        "        samples = np.array([])\n",
        "        for channel_idx in range(10):\n",
        "            plt.clf()\n",
        "            number = 20  #\n",
        "            h_r = np.random.normal(scale=np.sqrt(2) / 2)\n",
        "            h_i = np.random.normal(scale=np.sqrt(2) / 2)\n",
        "            h_r = np.tile(h_r, number)\n",
        "            h_i = np.tile(h_i, number)\n",
        "            for idx in range(len(mean_set_QAM)):\n",
        "                labels_index = np.tile(idx, number)\n",
        "                h_complex = h_r + 1j * h_i\n",
        "                # labels_index = np.random.choice(len(mean_set_QAM), number)\n",
        "                data_t = mean_set_QAM[labels_index]\n",
        "                transmit_data = h_complex * data_t\n",
        "                # print(\"shapes\", transmit_data.shape, h_complex.shape, data_t.shape)\n",
        "                transmit_data = np.hstack((np.real(transmit_data).reshape(len(transmit_data), 1),\n",
        "                                           np.imag(transmit_data).reshape(len(transmit_data), 1)))\n",
        "                gaussion_random = np.random.multivariate_normal([0, 0], [[0.03, 0], [0, 0.03]], number).astype(\n",
        "                    np.float32)\n",
        "                received_data = transmit_data + gaussion_random\n",
        "                conditioning = np.hstack(\n",
        "                    (np.real(data_t).reshape(len(data_t), 1), np.imag(data_t).reshape(len(data_t), 1),\n",
        "                     h_r.reshape(len(data_t), 1), h_i.reshape(len(data_t), 1))) /3\n",
        "                samples_component = sess.run(G_sample, feed_dict={Z: sample_Z((number, Z_dim)), Condition: conditioning})\n",
        "                plt.plot(samples_component[:, 0], samples_component[:, 1], colors[idx])\n",
        "                plt.plot(transmit_data[:, 0], transmit_data[:, 1], colors[idx])\n",
        "                #plt.plot(samples_component[:, 0], samples_component[:, 1], 'k.')\n",
        "                #plt.plot(transmit_data[:, 0], transmit_data[:, 1], 'b*')\n",
        "            axes = plt.gca()\n",
        "            axes.set_xlim([-4, 4])\n",
        "            axes.set_ylim([-4, 4])\n",
        "            xlabel = r'$Re\\{y_n\\}$'\n",
        "            ylabel = r'$Imag\\{y_n\\}$'\n",
        "            plt.xlabel(xlabel)\n",
        "            plt.ylabel(ylabel)\n",
        "            plt.show()\n",
        "            plt.savefig( save_fig_path + '/' + str(channel_idx) + '_{}_noise_1.eps'.format(str(i).zfill(3)),\n",
        "                        bbox_inches='tight')\n",
        "            plt.savefig(save_fig_path + '/' + str(channel_idx) + '_{}_noise_1.png'.format(str(i).zfill(3)),\n",
        "                        bbox_inches='tight')\n",
        "\n",
        "        axes.set_xlim([-4, 4])\n",
        "        axes.set_ylim([-4, 4])\n",
        "        plt.title('Iter: {}, loss(D): {:2.2f}, loss(G):{:2.2f}'.format(it + 1, D_loss_curr, G_loss_curr))\n",
        "        plt.savefig(save_fig_path + '/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
        "\n",
        "        i += 1"
      ],
      "metadata": {
        "id": "xQo1WYOjP5It"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "42MZG7Nn_QJE"
      }
    }
  ]
}